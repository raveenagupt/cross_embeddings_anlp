{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyOKPA4NWTjnWvwA5kjftvuq"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","from torch.utils.data import Dataset, DataLoader\n","from transformers import AutoTokenizer, AutoModel\n","import pandas as pd\n","from datasets import load_dataset\n","from tqdm import tqdm\n","\n","device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","print(\"Device:\", device)\n","\n","# ==========================================\n","# 1. Load Encoders + Tokenizers\n","# ==========================================\n","tokenizer_en = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n","tokenizer_zu = AutoTokenizer.from_pretrained(\"MoseliMotsoehli/zuBERTa\")\n","\n","# ------------------------------------------\n","# Encoder wrapper with projection\n","# ------------------------------------------\n","class EncoderWrapper(nn.Module):\n","    def __init__(self, model_name, proj_dim=256):\n","        super().__init__()\n","        self.encoder = AutoModel.from_pretrained(model_name)\n","\n","        # freeze encoder\n","        for p in self.encoder.parameters():\n","            p.requires_grad = False\n","\n","        self.proj = nn.Linear(self.encoder.config.hidden_size, proj_dim)\n","\n","    def forward(self, ids, mask):\n","        out = self.encoder(ids, attention_mask=mask)\n","        cls = out.last_hidden_state[:, 0, :]\n","        p = self.proj(cls)\n","        return nn.functional.normalize(p, dim=1)\n","\n","model_en = EncoderWrapper(\"bert-base-uncased\").to(device)\n","model_zu = EncoderWrapper(\"MoseliMotsoehli/zuBERTa\").to(device)\n","\n","# ==========================================\n","# 2. Load SST-2 sentiment (English)\n","# ==========================================\n","sst = load_dataset(\"glue\", \"sst2\")\n","sst_sentences = sst[\"train\"][\"sentence\"]\n","sst_labels = torch.tensor(sst[\"train\"][\"label\"])\n","\n","print(\"Loaded SST-2:\", len(sst_sentences))\n","\n","# ==========================================\n","# 3. Dataset for (EN–ZU + EN sentiment)\n","# ==========================================\n","class ContrastiveSentimentDataset(Dataset):\n","    def __init__(self, parallel_csv, tokenizer_en, tokenizer_zu,\n","                 sst_sentences, sst_labels, max_len=64):\n","\n","        df = pd.read_csv(parallel_csv)\n","        self.en_parallel = df[\"en\"].tolist()\n","        self.zu_parallel = df[\"zu\"].tolist()\n","\n","        self.sst_sentences = sst_sentences\n","        self.sst_labels = sst_labels.tolist()\n","\n","        self.tokenizer_en = tokenizer_en\n","        self.tokenizer_zu = tokenizer_zu\n","        self.max_len = max_len\n","\n","    def __len__(self):\n","        return len(self.en_parallel)\n","\n","    def __getitem__(self, idx):\n","\n","        # parallel EN / ZU\n","        en_enc = self.tokenizer_en(\n","            self.en_parallel[idx], truncation=True, padding=\"max_length\",\n","            max_length=self.max_len, return_tensors=\"pt\"\n","        )\n","        zu_enc = self.tokenizer_zu(\n","            self.zu_parallel[idx], truncation=True, padding=\"max_length\",\n","            max_length=self.max_len, return_tensors=\"pt\"\n","        )\n","\n","        # sentiment example (random EN sentence)\n","        s_idx = torch.randint(0, len(self.sst_sentences), (1,)).item()\n","        s_text = self.sst_sentences[s_idx]\n","        s_lab = self.sst_labels[s_idx]\n","\n","        s_enc = self.tokenizer_en(\n","            s_text, truncation=True, padding=\"max_length\",\n","            max_length=self.max_len, return_tensors=\"pt\"\n","        )\n","\n","        return {\n","            \"en_ids\": en_enc[\"input_ids\"].squeeze(),\n","            \"en_mask\": en_enc[\"attention_mask\"].squeeze(),\n","\n","            \"zu_ids\": zu_enc[\"input_ids\"].squeeze(),\n","            \"zu_mask\": zu_enc[\"attention_mask\"].squeeze(),\n","\n","            \"sent_ids\": s_enc[\"input_ids\"].squeeze(),\n","            \"sent_mask\": s_enc[\"attention_mask\"].squeeze(),\n","            \"label\": torch.tensor(s_lab),\n","        }\n","\n","# ==========================================\n","# 4. Losses\n","# ==========================================\n","def contrastive_loss(en_emb, zu_emb, temperature=0.05):\n","    N = en_emb.size(0)\n","    labels = torch.arange(N).to(en_emb.device)\n","\n","    sim = en_emb @ zu_emb.t() / temperature\n","    sim_t = zu_emb @ en_emb.t() / temperature\n","\n","    ce = nn.CrossEntropyLoss()\n","    return (ce(sim, labels) + ce(sim_t, labels)) / 2\n","\n","class SentimentHead(nn.Module):\n","    def __init__(self, dim):\n","        super().__init__()\n","        self.fc = nn.Linear(dim, 2)\n","    def forward(self, x):\n","        return self.fc(x)\n","\n","# ==========================================\n","# 5. Joint Training Loop\n","# ==========================================\n","def train_joint(parallel_csv, epochs=5, batch_size=16, lambda_sent=1.0):\n","\n","    dataset = ContrastiveSentimentDataset(\n","        parallel_csv, tokenizer_en, tokenizer_zu,\n","        sst_sentences, sst_labels\n","    )\n","    loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n","\n","    sentiment_head = SentimentHead(256).to(device)\n","    ce = nn.CrossEntropyLoss()\n","\n","    params = (\n","        list(model_en.proj.parameters()) +\n","        list(model_zu.proj.parameters()) +\n","        list(sentiment_head.parameters())\n","    )\n","\n","    opt = torch.optim.AdamW(params, lr=2e-4)\n","\n","    for epoch in range(epochs):\n","        total_loss = 0\n","\n","        for batch in tqdm(loader, desc=f\"Epoch {epoch+1}\"):\n","\n","            en_emb = model_en(batch[\"en_ids\"].to(device), batch[\"en_mask\"].to(device))\n","            zu_emb = model_zu(batch[\"zu_ids\"].to(device), batch[\"zu_mask\"].to(device))\n","\n","            loss_con = contrastive_loss(en_emb, zu_emb)\n","\n","            sent_emb = model_en(batch[\"sent_ids\"].to(device), batch[\"sent_mask\"].to(device))\n","            sent_logits = sentiment_head(sent_emb)\n","            loss_sent = ce(sent_logits, batch[\"label\"].to(device))\n","\n","            loss = loss_con + lambda_sent * loss_sent\n","\n","            opt.zero_grad()\n","            loss.backward()\n","            opt.step()\n","\n","            total_loss += loss.item()\n","\n","        print(f\"Epoch {epoch+1} Loss: {total_loss / len(loader):.4f}\")\n","\n","    torch.save(model_en.proj.state_dict(), \"proj_en.pt\")\n","    torch.save(model_zu.proj.state_dict(), \"proj_zu.pt\")\n","    torch.save(sentiment_head.state_dict(), \"sentiment_head.pt\")\n","\n","    print(\"Saved: proj_en.pt, proj_zu.pt, sentiment_head.pt\")\n","\n","    return\n","\n","# ==========================================\n","# 6. Run Training\n","# ==========================================\n","train_joint(\"en-zu.training.csv\", epochs=5, batch_size=16, lambda_sent=1.0)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TxgfvZ3pzh0i","executionInfo":{"status":"ok","timestamp":1763081896579,"user_tz":300,"elapsed":255408,"user":{"displayName":"Raveena Gupta","userId":"06103734461678506047"}},"outputId":"9ccb73ed-8a78-4348-fe76-6f04bba5eb30"},"execution_count":41,"outputs":[{"output_type":"stream","name":"stdout","text":["Device: cuda\n","Loaded SST-2: 67349\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 1: 100%|██████████| 297/297 [00:49<00:00,  6.04it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1 Loss: 2.1127\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 2: 100%|██████████| 297/297 [00:46<00:00,  6.45it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 2 Loss: 1.3756\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 3: 100%|██████████| 297/297 [00:47<00:00,  6.26it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 3 Loss: 1.0851\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 4: 100%|██████████| 297/297 [00:46<00:00,  6.36it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 4 Loss: 0.9047\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 5: 100%|██████████| 297/297 [00:47<00:00,  6.32it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch 5 Loss: 0.7798\n","Saved: proj_en.pt, proj_zu.pt, sentiment_head.pt\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}]},{"cell_type":"code","source":["import torch\n","import numpy as np\n","from transformers import AutoTokenizer, AutoModel\n","from datasets import load_dataset\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","# 1. Load the Zulu sentiment dataset\n","ds = load_dataset(\"michsethowusu/zulu-sentiments-corpus\")\n","zulu_texts = ds[\"train\"][\"text\"] if \"text\" in ds[\"train\"].column_names else ds[\"train\"][\"Zulu\"]\n","zulu_labels = ds[\"train\"][\"sentiment\"]\n","label_map = {\"Negative\": 0, \"Positive\": 1}\n","y_true = np.array([label_map[l] for l in zulu_labels])\n","\n","print(\"Loaded Zulu dataset: total examples =\", len(zulu_texts))\n","\n","# 2. Load your model components\n","tokenizer_zu = AutoTokenizer.from_pretrained(\"MoseliMotsoehli/zuBERTa\")\n","class EncoderWrapper(nn.Module):\n","    def __init__(self, model_name, proj_dim=256):\n","        super().__init__()\n","        self.encoder = AutoModel.from_pretrained(model_name)\n","        for p in self.encoder.parameters():\n","            p.requires_grad = False\n","        self.proj = nn.Linear(self.encoder.config.hidden_size, proj_dim)\n","    def forward(self, ids, mask):\n","        out = self.encoder(ids, attention_mask=mask)\n","        cls = out.last_hidden_state[:, 0, :]\n","        p = self.proj(cls)\n","        return nn.functional.normalize(p, dim=1)\n","\n","model_zu = EncoderWrapper(\"MoseliMotsoehli/zuBERTa\", proj_dim=256).to(device)\n","model_zu.proj.load_state_dict(torch.load(\"proj_zu.pt\", map_location=device))\n","model_zu.eval()\n","\n","class SentimentHead(nn.Module):\n","    def __init__(self, dim):\n","        super().__init__()\n","        self.fc = nn.Linear(dim, 2)\n","    def forward(self, x):\n","        return self.fc(x)\n","\n","sentiment_head = SentimentHead(256).to(device)\n","sentiment_head.load_state_dict(torch.load(\"sentiment_head.pt\", map_location=device))\n","sentiment_head.eval()\n","\n","# 3. Prediction loop (may batch for speed)\n","preds = []\n","batch_size = 32\n","for i in range(0, len(zulu_texts), batch_size):\n","    batch_texts = zulu_texts[i:i+batch_size]\n","    enc = tokenizer_zu(batch_texts, return_tensors=\"pt\", truncation=True,\n","                       padding=True, max_length=64).to(device)\n","    with torch.no_grad():\n","        emb = model_zu(enc[\"input_ids\"], enc[\"attention_mask\"])\n","        logits = sentiment_head(emb)\n","        batch_preds = torch.argmax(logits, dim=1).cpu().numpy()\n","    preds.extend(batch_preds)\n","\n","preds = np.array(preds)\n","\n","# 4. Compute accuracy\n","accuracy = (preds == y_true[:len(preds)]).mean()\n","print(f\"Zero‑shot Zulu Sentiment Accuracy: {accuracy*100:.2f}%\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_VMBu4uH4-PS","executionInfo":{"status":"ok","timestamp":1763082586652,"user_tz":300,"elapsed":239030,"user":{"displayName":"Raveena Gupta","userId":"06103734461678506047"}},"outputId":"aec0dd29-4492-49c8-ee87-4c0d00aba9a9"},"execution_count":44,"outputs":[{"output_type":"stream","name":"stdout","text":["Loaded Zulu dataset: total examples = 187435\n","Zero‑shot Zulu Sentiment Accuracy: 48.04%\n"]}]}]}